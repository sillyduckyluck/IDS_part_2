{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b25b95a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Introduction into Data Science - Assignment Part II\n",
    "\n",
    "This is the second part of the assignment in IDS 2023/2024.\n",
    "\n",
    "This part of the assignment consists of five questions â€” each of these questions is contained in a separate Jupyter notebook:\n",
    "- [Question 1: Data Preprocessing](Q1_Preprocessing_Visualization.ipynb)\n",
    "- [Question 2: Association Rules](Q2_Frequent_Itemsets_Association_Rules.ipynb)\n",
    "- [Question 3: Process Mining](Q3_Process_Mining.ipynb)\n",
    "- [Question 4: Text Mining](Q4_Text_Mining.ipynb)\n",
    "- [Question 5: Big Data](Q5_Big_Data.ipynb)\n",
    "\n",
    "Additional required files are in two folders.\n",
    "- [datasets](datasets/)\n",
    "- [scripts](scripts/)\n",
    "\n",
    "Please use the provided notebook to work on the questions. When you are done, upload your version of each of the notebooks to Moodle. Your submission will, therefore, consist of five jupyter notebook and _no_ additional file. Any additionally provided files will not be considered in grading.\n",
    "Enter your commented Python code and answers in the corresponding cells. Make sure to answer all questions in a clear and explicit manner and discuss your outputs. _Please do not change the general structure of this notebook_. You can, however, add additional markdown or code cells if necessary. Please **DO NOT CLEAR THE OUTPUT** of the notebook you are submitting! Additionally, please ensure that the code in the notebook runs if placed in the same folder as all of the provided files, delivering the same outputs as the ones you submit in the notebook. This includes being runnable in the bundled conda environment.\n",
    "\n",
    "*Please make sure to include the names and matriculation numbers of all group members in the provided slots in each of the notebooks.* If a name or a student id is missing, the student will not receive any points.\n",
    "\n",
    "Hint 1: **Plan your time wisely.** A few parts of this assignment may take some time to run. It might be necessary to consider time management when you plan your group work. Also, do not attempt to upload your assignment at the last minute before the deadline. This often does not work, and you will miss the deadline. Late submissions will not be considered.\n",
    "\n",
    "Hint 2: RWTHMoodle allows multiple submissions, with every new submission overwriting the previous one. **Partial submissions are possible and encouraged.** This might be helpful in case of technical issues with RWTHMoodle, which may occur close to the deadline.\n",
    "\n",
    "Hint 3: As a technical note. Some IDEs such as DataSpell may automatically strip jupyter notebook cell metadata. If you are able, please re-add it from the source notebooks before submission. This is necessary for our grading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a9d89",
   "metadata": {},
   "source": [
    "Enter your group number and members with matriculation numbers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457e5e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T14:39:43.463127500Z",
     "start_time": "2023-12-12T14:39:43.450885200Z"
    }
   },
   "outputs": [],
   "source": [
    "GROUP_NO = 123 # group number\n",
    "GROUP_MEMBERS = {\n",
    "    123456: \"firstname lastname\", # mat. no. : name,\n",
    "    234567: \"firstname lastname\",\n",
    "    345678: \"firstname lastname\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8f23f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30acff93-801f-434f-ab12-538ebba149c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3a98fb84f5a31558222af77538151c0",
     "grade": false,
     "grade_id": "cell-34ae91f58bb3ca62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# required imports\n",
    "# do not edit!\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import unicodedata\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # omw = open multilingual wordnet\n",
    "stopword_list = set(stopwords.words('english'))\n",
    "reg_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")  # tokenizes and removes punctuation at the same time\n",
    "snow_stemmer = SnowballStemmer('english')\n",
    "wordnet_lemmatizer = WordNetLemmatizer();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d487223-5415-47c9-8034-4ac6668dd837",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66e76c0ae57023579fb3d9917423054f",
     "grade": false,
     "grade_id": "cell-0118f620e3b16e5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Question 4: Text Mining (23 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526aa733-b2cb-43b1-8aa5-3b1d0940b826",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c95eddc9166bd9d238e1c7f2dc34146",
     "grade": false,
     "grade_id": "cell-91cc44ba05ec7bca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## About the Data: Taylor Swift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747a235-a8a3-4cb4-949e-94f6ab7fd1ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "abcd8d5cc7967fea2e023876b62e846a",
     "grade": false,
     "grade_id": "cell-51d9f6ad0d201523",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this task, our data consists of song lyrics from nine albums by Taylor Swift. Taylor Swift is one of the best-selling musicians and currently subject of various research. As she is known to venture into different musical genres and make artistic innovations for each album, we want to check whether we can support this claim using Text Mining.\n",
    "\n",
    "Therefore, we:\n",
    "1. Load the data and preprocess it first,\n",
    "2. use the set of words for recognizing a lyric's album,\n",
    "3. use Doc2Vec to check the similarity of albums and to cluster them,\n",
    "4. and finally use language models that are based on n-grams to generate some own lyrics.\n",
    "\n",
    "We aim to support our data analysis by reporting data and discussing results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d140f-e798-48c1-8adf-c4c483ee63a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c6c40532cc936e6553de062a5a58cbf",
     "grade": false,
     "grade_id": "cell-a7e968abe2c820c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data Loading and Preprocessing (7.5 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cfeb67-3be6-4177-b107-a3855f665d83",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6da2454d5d180ea66b0a0d70c28fdc12",
     "grade": false,
     "grade_id": "cell-cadbb00abe70693d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### a)\n",
    "i. First things first. Import the file **q4_taylor_swift.csv** and save it into a dataframe named `swift_df`. Visualize the dataframe by showing the first five lines. \n",
    "\n",
    "_Note: In this question, every lyric is considered as a single document. The data contains lyrics from several albums. The order of the lyrics is preserved considering their album, song and within their song._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5261d6-89cb-432d-8276-60b2629d4bb8",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e23e1669f31c56ab8a1bcfbe1e9be5c4",
     "grade": false,
     "grade_id": "cell-74423eee5348219e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import and visualization.\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbec108-c03f-4ff7-b3b1-2f354f411f26",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "edcbb65e470aa8fc002f5bc95926bb92",
     "grade": false,
     "grade_id": "cell-2c1984ef3edd32c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "ii. As a first step in preprocessing, normalize all unicode encodings using `unicodedata.normalize` with 'NKFD' as the form and remove all closing and opening brackets, i.e., '(' and ')'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d9e0c-5885-4401-be01-6e96714f6e21",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73ff39a023325dd9553977985f03371e",
     "grade": false,
     "grade_id": "cell-05b0e924b2a3bd14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d31c2d-7f26-40f5-9481-f9bf5c82dd15",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "721aa7dfcb6bf5b12b04a345b6503de8",
     "grade": true,
     "grade_id": "cell-170ed699bf34315e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbc2b684-f834-4d03-8912-963eb0626699",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08c84420e0adb2e9a2cfc1df7bab6703",
     "grade": false,
     "grade_id": "cell-fd2a2f622f0afb7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### b)\n",
    "We get a first idea of the data distribution over the albums by counting the lyrics in our data per album. Code the method `count_lyrics_per_album`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05055434-3e7d-4177-9618-ea923dbabd66",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fd0a655faef2debc2190a90d61ff646",
     "grade": false,
     "grade_id": "cell-97a41ea0fa2ef0e3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def count_lyrics_per_album(input_df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Counts the lyrics for each album and stores them in a pandas series.\n",
    "    :param input_df: A pandas dataframe containing album data and their lyrics.\n",
    "    :return: The data containing the albums and the count of lyrics per album.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60440407-85a2-40c8-b2ee-83cc70536731",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdd5762827d237dc139a8889e774973b",
     "grade": false,
     "grade_id": "cell-35f7a0fbcc8c518a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Using the predefined function to calculate the series of values\n",
    "count_per_album = count_lyrics_per_album(swift_df)\n",
    "\n",
    "# Transforming the series to a dataframe for visualization - feel free to check the series object\n",
    "pd.DataFrame({'album': count_per_album.index, 'lyric count': count_per_album.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75b38b-212b-4ac8-bdee-ff084e54b79e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b3840d6512a4a7d2d40d86cd0e07355",
     "grade": true,
     "grade_id": "cell-af1402574d78e045",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfefcf23-486e-4973-b288-35db298b6b84",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff78c9216fe9550c8b32cbde69b50b3d",
     "grade": false,
     "grade_id": "cell-fc95e893dd9f622f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### c)\n",
    "i. Next, we visualize the counted lyrics per album using a barplot. Write down your code in `plot_lyric_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543ceb2-7c6a-4a55-981d-d426134005c4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aed2c04d548c860df877f4f6ada11040",
     "grade": true,
     "grade_id": "cell-41abba85a692335e",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_lyric_count(input_series: pd.Series):\n",
    "    \"\"\" \n",
    "    Visualizes the number of lyrics for each album in a bar plot.\n",
    "    :param input_series: A pandas series containing album data and their lyric counts.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Sasha - love\n",
    "    # Tian - dream\n",
    "    # Rami - heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b854f-a5b1-4e6b-a6dd-0a97992e5865",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c07c3e20e1dc41b1f7ef07601577e07",
     "grade": false,
     "grade_id": "cell-7111f48ce681203e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing the data of 'count_per_album' as a bar plot using your function\n",
    "plot_lyric_count(count_per_album)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007a4c0-40a2-49a1-a1be-a97e9a6544dc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f966e28c8e113018f9b6c45852d40a6",
     "grade": false,
     "grade_id": "cell-8fd5a89b5f967915",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "ii. Is the data balanced enough for album classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1736e34-b919-43bf-86b0-a0ead2aa866c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0838ca91f05b637c0b531f4e2f14703d",
     "grade": true,
     "grade_id": "cell-d5c991ee6c16e792",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "__Student Answer:__ _your answer goes here_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a50ad-79cd-44a0-adea-4c22f5a145e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58d7fd1d2bf59e7bd8556aa4926d0db4",
     "grade": false,
     "grade_id": "cell-7e70930f57bc2137",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### d)\n",
    "In the following, we want to remove duplicate lyrics, as a song may contain a lyric more than once. Removing duplicates improves the interpretability of the further analysis and reduces an overfitting of the classification task on the duplicated lyrics. \n",
    "\n",
    "i. Therefore, as a first step, we remove all duplicate lyrics and keep only a single instance per duplicate lyric on each album. The obtained dataset has to be named `swift_df_proc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb347c2-a30a-4260-9fda-4b740760cc7a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76d4f5d22e3655cbd2f3dc45e691654b",
     "grade": false,
     "grade_id": "cell-081438fb30f61c00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Dropping all duplicates of a lyric on an album\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8067eb-25c5-49f0-b453-54a32ca7285c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bad96bb85bd06dd028e286345128b78",
     "grade": true,
     "grade_id": "cell-2a1f3798c1a99aae",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d802f45-48cb-42e5-98fc-90403d64b85d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28fc4921eafae57b336db1339aed29c3",
     "grade": false,
     "grade_id": "cell-ed8a25ffaa9b22e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "ii. Do lyrics occur in several albums? If this is the case, remove them entirely as such a lyric is not suitable for our further questions. If this is not the case, give the code that shows so. Remember also to give a clear answer below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674336cd-9721-42d4-a614-525fb4cd9c79",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2306d063086f14a6377a491e634dc274",
     "grade": false,
     "grade_id": "cell-a9faaa90a5b85029",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800aa956-f9c2-4b54-8a68-0707b198bb55",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba4f5a291a8aa04a12167e9673aa0366",
     "grade": true,
     "grade_id": "cell-164c891ecf7548d0",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "__Student Answer:__ _your answer goes here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f2b3a-90e5-4397-bd48-363978c3355c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "badd4d86dc0a5903a0c296c291203947",
     "grade": true,
     "grade_id": "cell-bc6dc589a24f5940",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74195a-9ce2-491e-bf56-30dca6f2b85a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ea6c90728f5a29e9e48becf3703f500",
     "grade": false,
     "grade_id": "cell-87a8b88eea966d3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_lyric_count(count_lyrics_per_album(swift_df_proc))\n",
    "count_lyrics_per_album(swift_df_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3252aa3e-ffe5-4016-a861-a1bfef708d6d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a55083b758c06364cd1cb169261cd61",
     "grade": false,
     "grade_id": "cell-abd64a70e8132966",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### e)\n",
    "The following tasks are more related to the preprocessing that has to be applied for the Text Mining context. First of all, we have to create a corpus. The obtained corpus should be named `corpus`. Make sure that each document in the corpus corresponds to exactly one lyric in `swift_df_proc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad9fad-7b6b-4d65-9bd4-926dff770f7c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4363f9f25282091bb4cb56b18906e79",
     "grade": true,
     "grade_id": "cell-d9b7f136d978368c",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating the corpus\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52199265-b547-4197-8623-a6e1c8503196",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a14a58028f6b1c32f1ab830786dbdefe",
     "grade": false,
     "grade_id": "cell-fcda43d7485c7cac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### f)\n",
    "Use the skeleton of the function `preprocessor_func` below to create a function that applies tokenization, stopword removal and lemmatization to an input string. The remaining tokens (after stopword removal and lemmatization) should be joined using a whitespace (' ')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6222e4-3e38-4567-a1e1-3f99ed48ada0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31b2a41f36d158ea9349d00fdd0fe841",
     "grade": true,
     "grade_id": "cell-0285aeb5ccf544a4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocessor_func(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocesses a string using tokenization, stopword removal and lemmatization.\n",
    "    :param text: A string to be preprocessed.\n",
    "    :return: A joined string resulting from tokenization, stopword removal and lemmatization of an input string.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf80fa-ecbf-4d38-8f08-2a728fc15e07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd62af3ec279d71fe41a6cb2c8b30683",
     "grade": false,
     "grade_id": "cell-3441db3ab6720ce4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### g)\n",
    "Now, create a preprocessed corpus `corpus_proc` by applying the preprocessing function to your corpus. For some tasks, we have to use the preprocessed corpus, and for some, the original corpus. This is indicated for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4249d-6bcb-4277-b4d8-377250e11f77",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9279503c9feb5fdc9d0a296492c6264",
     "grade": true,
     "grade_id": "cell-ac0bcb85911e4d04",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Corpus preprocessing\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f71344-dc17-4457-a0fa-85d916769c11",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f624f7c17b98de9258833f86ad3da9ed",
     "grade": false,
     "grade_id": "cell-049bd0a6aba58dbc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### h)\n",
    "In this task, we create all preprocessed data for all remaining tasks within the Text Mining question exercise.\n",
    "For the later application of the set of words, we need to split the corpus.\n",
    "First, we need to split our input data into a train and test set according to the Pareto rule (80% training set size and 20% test set size).\n",
    "Therefore, split the dataframe `swift_df_proc` into a training and test set using the variable identifiers `df_train`, `df_test`, `y_train`, and `y_test`.\n",
    "Further, make sure that distribution based on the \"album\" value is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119013af-d8dd-4085-ac77-ee23178b6366",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff8f5e447720ab016fde7de2da4039fd",
     "grade": true,
     "grade_id": "cell-bf9906ca7bc81fc7",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b84cd2-5f2c-4fc9-810b-611437baa0db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9ea3eda0c4223a80409cbcb019c38d6",
     "grade": false,
     "grade_id": "cell-79f4d05b015e7fdc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### i)\n",
    "Lastly, we create two further corpora, `corpus_train` and `corpus_test`, using the split data and the identical approach that is used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d72ce-96c5-4914-8c55-cad75bf6a378",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6e85c1d4037daad61701b5549ca243f",
     "grade": true,
     "grade_id": "cell-f95f2e1ee0704677",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7975ec-28ee-49cb-99c6-b8507cd82433",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd6fe678d0d20804f8ae94d7e5a6f154",
     "grade": false,
     "grade_id": "cell-45c3d55087d2210e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Set of Words (6 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7494a7-a797-4596-9fe7-484c083dd9a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31db04f8b803d54bc9f04102a1bddc56",
     "grade": false,
     "grade_id": "cell-6996ea2f614f429f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this subtask, we use the set of words technique to distinguish and recognize different lyrics based on which album they belong to. Set of words encodes the documents by indicating for each word in our vocabulary whether the word occurs in the sentence or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b542a3c-bf20-42b2-973c-f0753215454c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "251a1bb5b6197fe5ce956f3edf776d77",
     "grade": false,
     "grade_id": "cell-dc89d813750c9d3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### j)\n",
    "Create a set of words encoding for the whole corpus. Use the previously defined preprocessor function `preprocessor_func` for our corpus `corpus`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf82eea-9a3f-4447-9ea1-ce80aa4d859d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "390bf1ff246b4bd8f751345e58f8f941",
     "grade": true,
     "grade_id": "cell-6c6783a12fc93671",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating a set of words using the propressor function and the corpus\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b4239-6704-435a-8e2e-d304dd50ea54",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8b729efbb4dde4ca80183d275bdcfdd",
     "grade": false,
     "grade_id": "cell-214105d7e290a6f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### k)\n",
    "In the following, we want to have a first look at how the set of words classification works. Therefore, we apply the set of words to a line in the `swift_df`. Use the `apply_sow_to_line_by_index` function that is given an index of a lyric and that returns the original line, its preprocessed form, and its encoding resulting from the set of words implementation.\n",
    "Comment below on what information the set of words representation contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41180a1c-5538-42e9-9ed9-9fc6c208fe7f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e555d6ebc795c991b0f01278bb3b16a",
     "grade": false,
     "grade_id": "cell-86967ce48efc320b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def apply_sow_to_lyric_by_index(index: int) -> (str, str, _):\n",
    "    \"\"\" \n",
    "    Applies set of words to a lyric in the swift_df.\n",
    "    :param index: The index of the chosen lyric entry.\n",
    "    :return: The function returns the chosen lyric, it preprocessed form and the set of words representation. \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d01e95-2a45-484c-a59b-4b9f6bafd0ca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e4ae45f00eb47497f78956edaa9db40",
     "grade": false,
     "grade_id": "cell-1141cb919a989210",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdef059-c51a-44b0-aa82-094597913089",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cf35baca1700074f34c343123a206f7",
     "grade": false,
     "grade_id": "cell-4066c15907913eab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "line, line_p, line_sow = apply_sow_to_lyric_by_index(index)\n",
    "print('Original line:     ', line)\n",
    "print('Preprocessed line: ', line_p)\n",
    "print('SoW encoding:\\n', line_sow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f3131-4ba1-47cb-af28-0b8fb08a25a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "964b2def2d29e1cb1491c47f004aa1ab",
     "grade": true,
     "grade_id": "cell-10d8a3a1768df6d7",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1376d3c-27e0-4235-ae10-c106b9479c76",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86d5b5a33c9cf1129703b10c2b2862a9",
     "grade": true,
     "grade_id": "cell-7be127e646369a3f",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "__Student Answer:__ _your answer goes here_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350c65a-119e-45c2-863e-88141e005e87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13735251bdf64f9f3cbcae0781f9962a",
     "grade": false,
     "grade_id": "cell-bbb6843160af58b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### l)\n",
    "In this subtask, we use a **S**tochastic **G**radient **D**escent classifier to predict the album given a lyric for the corpus. Therefore, the steps to follow are briefly described below:\n",
    " 1. First, we create a set of words encoding for the whole corpus. As we want to evaluate our results later using the test set, restrict yourself in the training to only use the training set `corpus_train`. \n",
    " 2. Train the classifier on the training set with 'album' as the target feature and 'log_loss' as the loss function.\n",
    " 3. Predict the album for each line in the training and test set `corpus_test`.\n",
    " 4. Calculate and show the accuracy for both the training and test set and store them in the variables `accuracy_train` and `accuracy_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9fa24-c247-47dc-b72f-f3c9e2c8c30e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53d9bd43d558ad0123bf1049ecd2e7c1",
     "grade": true,
     "grade_id": "cell-b3c5060ceb18d74f",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating the set of words encoding\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cea26b-dec4-420e-a072-f32f07a0d7fd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e306261549a90e052380ebccb7889fd",
     "grade": true,
     "grade_id": "cell-ae9e71cbd2e1ca0d",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1553d8d-0536-442f-bff1-40b96def410e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ebdbd10faf7d21631dbe3687d426a9c",
     "grade": true,
     "grade_id": "cell-4ed4c4a1b1bec6ee",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict the album\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615961f8-8133-413f-b749-f2d5eee1952a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e70c81b74cb920f54d28ff86dfe56018",
     "grade": true,
     "grade_id": "cell-c21343ac880f25b0",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute and show accuracy for training and test set\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e205dc-5562-48e6-ad88-0e5241d16994",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f91638623d40d19b3d5f29676dae780",
     "grade": false,
     "grade_id": "cell-614e0975e1f509af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### m)\n",
    "Given the accuracy values that you calculated in the last subtask, argue about the classifier's accuracy compared to a most frequent guessing classifier (i.e., a classifier that always chooses to predict the most frequent album). Use the distribution of lyrics over the albums calculated in task **a4)** to support your argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2439c5f-a0ee-4b79-8b18-0f95a79f1667",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "708a21f877730facd9c0c2ceed98fc50",
     "grade": true,
     "grade_id": "cell-6e5beedfdb7354ed",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "__Student Answer:__ _your answer goes here_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15c9c2-1566-40fe-b668-376aac576606",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa8cda6cc7a0115e180be72ad544276a",
     "grade": false,
     "grade_id": "cell-d795b66869ba2eb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### n)\n",
    "Next, we want to make our results more visual. Therefore, implement the `pred_album_by_index` method that takes a lyric's index as input, and based on that, returns the corresponding lyric, its actual album and its predicted album using the SGD classifier from **b3)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b2379-2623-4b64-864e-231ae197b618",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fe2a3010be4a835c276f78db44fd719",
     "grade": true,
     "grade_id": "cell-eb989103f1512c70",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pred_album_by_index(index: int) -> (str, str, str):\n",
    "    \"\"\" \n",
    "    Predicts a lyric's album based on the .\n",
    "    :param index: The index of the chosen lyric entry.\n",
    "    :return: The function returns the chosen lyric, it preprocessed form and the set of words representation. \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a0fc0-6237-4604-bcb0-10ab80b6ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = -1 # Please change the index and do not use -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c87af-fa31-467a-95e4-979330b9699b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "713dbff30fcc532b833bfed977459c55",
     "grade": false,
     "grade_id": "cell-38d17ee6b8ba0046",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lyric, album_actual, album_pred = pred_album_by_index(index)\n",
    "\n",
    "print(\"Lyric:          \", lyric)\n",
    "print(\"Actual album:   \", album_actual)\n",
    "print(\"Predicted album:\", album_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654587d7-1a19-4a80-83ff-7302160388b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9eb43a2b0289109c4189ac616293c18f",
     "grade": false,
     "grade_id": "cell-8ad4bf9ac59d61c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Doc2Vec (4.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e717b6-d60e-43db-a22d-a6597b6807c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f57ef484aebf33413416e8d74f8bb11",
     "grade": false,
     "grade_id": "cell-19b515bee8fe850f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this subtask, we encode lyrics using Doc2Vec. Given the embedding, we reduce its dimensionality using **P**rincipal **C**omponent **A**nalysis while preserving the maximum amount of information so that we can visualize and cluster the embeddings in a scatter plot. Lastly, we have a manual look at the clusters to evaluate the information gain of the Doc2Vec approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459d351-f946-4ccf-81fa-c51649b088c8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2114e9b2a2586497aeda7a0c6fc21a51",
     "grade": false,
     "grade_id": "cell-3a84f47bd25d5223",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### o) \n",
    "Initialize and train a Doc2Vec model based on the documents in the preprocessed corpus `corpus_p`. Set the vector dimension to 20 and min_count to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad43825-8049-4d98-a639-c0cb1ea1d1ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1d550ec9bc3d02e0013bfbeb8067033",
     "grade": true,
     "grade_id": "cell-1e76f60ed2ec69fd",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculating the number of cores available\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# There was once a man named Rami who came from the Holy Land. Rami was very smart and liked to make cocktails.\n",
    "\n",
    "# output\n",
    "# elephant [.5, .3, .02, 1, .4]\n",
    "# good [.1, .4, .2, 1, .5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b358d3b6-d765-488d-a3f4-83e2cddd4cfd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9bc3f1064970387afbe71bc65c3a9cc8",
     "grade": false,
     "grade_id": "cell-743af586a286d2ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### p)\n",
    "Create an embedding for each lyric in `swift_df_proc` and add all embeddings inferred to the `lyric_embeddings` list. This is a pretask for the next step that we take. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40cbc3-dbfe-4205-9bce-6ab3a408147c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11ffebd78c6cdea1b0ea02ebc78bee49",
     "grade": true,
     "grade_id": "cell-f0d28ba5b898a192",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lyric_embeddings = []\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a79a1f-d6f9-4f55-b9d8-42970997476f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d591d1dec884334d725fe6a1541a8b5a",
     "grade": false,
     "grade_id": "cell-b67a805ac7a79824",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### q)\n",
    "Store the data contained in `lyric_embeddings` in a dataframe `embeddings_df`.\n",
    "Apply DBSCAN to the `embeddings_df`dataframe with `eps = 0.3` and `min_samples = 2` and create a scatterplot with seaborn that shows the clusters of the inferred vectors. To be able to visualize the data in a two-dimensional vector space, apply a **p**rinciple **c**omponent **a**nalysis that is able to reduce the dimensionality of input data. (You can learn more about the PCA in its [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)). The code for the PCA is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427e70d-5720-41f6-956c-6ad2d896a3e3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f60f277c5500cb389ed1fe51127f696",
     "grade": true,
     "grade_id": "cell-32f6db6de61531a7",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Applying PCA to the embedding reducing the dimensionality to two\n",
    "pca = PCA(n_components=2)\n",
    "pca_embeddings = pd.DataFrame(pca.fit_transform(embeddings_df))\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0bfbe7-fcda-4bea-8334-599cfd6fa1da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27653aee4a24efa1cead7716b742f5e8",
     "grade": false,
     "grade_id": "cell-7400b05548128502",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### r)\n",
    "Show lyrics from the original `swift_df` dataframe contained in two distinct clusters using the two cells below. Answer separately, whether you consider the lyrics in each cluster to be similar or dissimilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64547d-8a45-4af2-b9a6-0b07cca92d8e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9f439ae99a1f370ee34440c8fce5ef1",
     "grade": true,
     "grade_id": "cell-eeee7c827574738a",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Lyrics contained in one cluster\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c4968-2551-40d4-918d-f725d8b8fa6a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73ab1311beb53e80b6f64c4f16e0368d",
     "grade": true,
     "grade_id": "cell-d721129580166953",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Lyrics contained in one cluster\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253f6c7-80b7-48b6-8866-e3bd36b4b872",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5209a1ff3eee4ac82dd4682f2c80d9d3",
     "grade": true,
     "grade_id": "cell-623be93e0b95082d",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "__Student Answer:__ _your answer goes here_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee33fcd-a77b-47c3-8089-70f421f03308",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1866385065537471eabc81a0bfba5ef3",
     "grade": false,
     "grade_id": "cell-dfab126c449f469d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## An N-Gram Based Language Model (4 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e9fe4-73d5-479a-9d6b-87f08df4ccc4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65d68f349de3b754666e34d2e99588e3",
     "grade": false,
     "grade_id": "cell-8c981d67a41ee089",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this subtask, we use the `swift_df` data to create an n-gram based language model to generate new lyrics. Therefore, we play around with different values for n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdeed80-b6c5-4e2c-a418-675b3b2a2599",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5512e92be18e7a451186177edde26805",
     "grade": false,
     "grade_id": "cell-0d30d6096b1d71c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### s)\n",
    "Write the `lyric_preprocessor` method that takes a lyric as input and that tokenizes it and makes each word lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb0e42-1c32-49c4-907d-c4fba3c4f14c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee48ca9b59ffd8d841e94ef90bb38a1f",
     "grade": true,
     "grade_id": "cell-92f26b558e186263",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lyric_preprocessor(lyric: str) -> [str]:\n",
    "    \"\"\"\n",
    "    Tokenizes a lyric and makes the tokens lowercase.\n",
    "    :param lyric: A string containing an input lyric.\n",
    "    :return: A list containing lowercase tokens of the input lyric.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# have a happy new year\n",
    "# have a happy new year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed77c05f-44ad-45a4-879f-e297c9363dbd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86fa9acd91446563bcfeb66448b351df",
     "grade": false,
     "grade_id": "cell-53fc779838099b3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### t)\n",
    "Apply the lyric_preprocessor to all lyrics in the `swift_df` and store the data in a `lyric_corpus` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250532eb-2ab2-4d50-a221-1d67fbe176d5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fad81dcf44ba09e0a5a90e23cc85f76",
     "grade": true,
     "grade_id": "cell-bdd197cdd0c9ce03",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa2548-060b-4062-9771-045ed6f4419d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad785d9231f3d4001188cab003e4f483",
     "grade": false,
     "grade_id": "cell-711b7562e81d4c8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, train two n-grams with $n \\in \\{2,5\\}$ on the lyric_corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ac896-0247-425d-9655-8c3975deced3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "344f804fcbc69fef3f793282addc0b2e",
     "grade": true,
     "grade_id": "cell-de35c5ee4c491b53",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602957a-0c02-4984-a082-26be35798295",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3590a31560b412701559f1de47b08511",
     "grade": false,
     "grade_id": "cell-312235d548c36588",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### u)\n",
    "i. Write the `generate_lyrics` method that takes an n-gram model and an integer for the number of lyrics to be generated as input and that returns a list of new lyrics that were generated using the given n-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43339aaa-9c05-4d31-9a61-0e46a6fc074b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4664804246c45d8fe567b7157918ab93",
     "grade": true,
     "grade_id": "cell-5f4a433494c2f516",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_lyrics(n_gram_model, numb_of_new_lyrics: int) -> [str]:\n",
    "    \"\"\"\n",
    "    Uses an n-gram model to generate several new lyrics.\n",
    "    :param n_gram_model: An n-gram model. \n",
    "    :param numb_of_new_lyrics: The number of lyrics to be created.\n",
    "    :return: As many generated lyrics as defined by the numb_of_new_lyrics.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266fce6-2d6d-4927-94e6-015669ce5a61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1306da555d42d6e0d7fbe62526e6956d",
     "grade": false,
     "grade_id": "cell-0d816b3d4e2f12fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "ii. Generate with the first and the second model ten lyrics each. Name one difference that you can find between the lyrics generated with 2-gram model and with the 5-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32961f-a40f-4568-aff5-b302afdc323d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65fe231a42bc41730a9d0b77eb1e4d66",
     "grade": true,
     "grade_id": "cell-bee841b2cbdd6856",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate and show ten lyrics with the first model\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef8ed9-fd00-4fea-8ac3-2cbbf822672e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b65301fe2f55941eddf96547c19e2e5",
     "grade": true,
     "grade_id": "cell-23fc0dadd9790843",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate and show ten lyrics with the first model\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de49ee-ac28-4a4b-82fa-424d55a34cbe",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8795bcf214d87d441d1f3e4eea529b3b",
     "grade": true,
     "grade_id": "cell-084b39ed28f0bad2",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "__Student Answer:__ _your answer goes here_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
